{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "558da971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ff3f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Torch tensors\n",
    "# Defining a one dimensional tensor\n",
    "a = torch.tensor([2,2,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2afe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Defining a two dimensional tensor\n",
    "b = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597d2a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([3])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# The size of the tensors \n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499cda29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#  Getting the Height/rows in b\n",
    "print(b.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c549e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining different datatypes of tensors\n",
    "# Float\n",
    "flo = torch.tensor([[1,2],[3,4]], dtype=torch.float)\n",
    "doub = torch.tensor([1,2], dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4754f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Getting the datatypes for the tensors\n",
    "print(flo.dtype)\n",
    "print(doub.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c21a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5000)\n",
      "tensor(1.2910)\n"
     ]
    }
   ],
   "source": [
    "# Fetching the mean and the standard deviation of a tensor\n",
    "print(flo.mean())\n",
    "print(flo.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d78e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6],\n",
      "        [7],\n",
      "        [8],\n",
      "        [9]])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "\n",
      " Tensor B after assigning new shape tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "\n",
      " The shape of tensor B is torch.Size([1, 9])\n",
      "tensor([[[ 0.0053, -0.1609, -0.4107, -0.5862],\n",
      "         [-0.5446,  0.2137, -0.8196,  1.3846],\n",
      "         [-0.5664,  0.2875, -0.8852, -1.4499]],\n",
      "\n",
      "        [[ 1.8488, -0.2969,  0.9424, -0.4392],\n",
      "         [-1.0954, -0.4682, -0.9525, -0.8017],\n",
      "         [ 1.6451,  0.3325,  1.2691, -1.1603]]])\n",
      "tensor([[ 0.0053, -0.1609, -0.4107, -0.5862, -0.5446,  0.2137, -0.8196,  1.3846,\n",
      "         -0.5664,  0.2875, -0.8852, -1.4499],\n",
      "        [ 1.8488, -0.2969,  0.9424, -0.4392, -1.0954, -0.4682, -0.9525, -0.8017,\n",
      "          1.6451,  0.3325,  1.2691, -1.1603]])\n",
      "tensor([[ 0.0053, -0.1609, -0.4107, -0.5862, -0.5446,  0.2137, -0.8196,  1.3846,\n",
      "         -0.5664,  0.2875, -0.8852, -1.4499],\n",
      "        [ 1.8488, -0.2969,  0.9424, -0.4392, -1.0954, -0.4682, -0.9525, -0.8017,\n",
      "          1.6451,  0.3325,  1.2691, -1.1603]])\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the tensors\n",
    "# If one of the given dimension is given -1 then the size can be inferred which means if for \n",
    "# it is given -1,3 then python will find our which nos of other dimensions are required is to satisfy x,-3\n",
    "# Pytorch will find out the x\n",
    "\n",
    "print(b.view(-1,1))\n",
    "print(b.view(9))\n",
    "\n",
    "# Assigning b a new shape\n",
    "b = b.view(1,-1)\n",
    "print(\"\\n Tensor B after assigning new shape {}\".format(b))\n",
    "print(\"\\n The shape of tensor B is {}\".format(b.shape))\n",
    "\n",
    "# Creating a 3D tensor with 2 channels 3 rows and 2 columns\n",
    "thre_dm = torch.randn(2,3,4)\n",
    "print(thre_dm)\n",
    "print(thre_dm.view(2,12))\n",
    "print(thre_dm.view(2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9266d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8375, 0.2254, 0.5141, 0.5167],\n",
      "        [0.5352, 0.8949, 0.0142, 0.4650],\n",
      "        [0.4123, 0.3908, 0.2343, 0.3667],\n",
      "        [0.7334, 0.9764, 0.2845, 0.0535]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a matrix with random nos in a range of 0 and 1\n",
    "rand = torch.rand(4,4)\n",
    "print(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9c4a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0976,  0.4659,  0.8670, -0.2110],\n",
      "        [-1.5707, -0.6930, -0.8440,  2.0431],\n",
      "        [ 0.4148,  0.6165, -0.6185, -0.8482],\n",
      "        [-0.8679, -0.0985, -1.2651, -0.6342]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Creating a matrix with random nos taken from a normal distribution with mean 0 and variance 1\n",
    "rand = torch.randn(4,4)\n",
    "print(rand)\n",
    "print(rand.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d620ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 8, 9, 7, 9])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a array of 5 random integers from values between 6 and 9 exclusive of 10\n",
    "in_arr = torch.randint(6,10, (5,))\n",
    "print(in_arr)\n",
    "print(in_arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f6a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 7, 7],\n",
      "        [9, 8, 7],\n",
      "        [9, 8, 6]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Creating a 2d array or matrix of size 3x3 filled with random integers from values between 6 and 9\n",
    "in_arr = torch.randint(6,10, (3,3))\n",
    "print(in_arr)\n",
    "print(in_arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c374d684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Fetching the nos of the elements in the above matrix\n",
    "print(torch.numel(in_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28e9a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Creating a 3x3 matrix of zeros of dtype long\n",
    "z = torch.zeros(3,3, dtype=torch.long)\n",
    "print(z)\n",
    "# Creating a 3x3 matrix of ones\n",
    "x = torch.ones(3,3)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42d35ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5560,  0.0656, -0.5199],\n",
      "        [ 0.0582,  0.1887, -0.0847],\n",
      "        [ 0.6055, -0.1418, -0.0297]], dtype=torch.float64)\n",
      "tensor([[2.5560, 1.0656, 0.4801],\n",
      "        [1.0582, 1.1887, 0.9153],\n",
      "        [1.6055, 0.8582, 0.9703]], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2.5560, 1.0656, 0.4801],\n",
       "        [1.0582, 1.1887, 0.9153],\n",
       "        [1.6055, 0.8582, 0.9703]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the tensors data type\n",
    "xlike = torch.randn_like(x, dtype=torch.double)\n",
    "print(xlike)\n",
    "\n",
    "# Adding two tensors \n",
    "summation = torch.add(x,xlike)\n",
    "print(summation)\n",
    "\n",
    "# Inplace summation\n",
    "x.add_(xlike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b36e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5560, 1.0656, 0.4801],\n",
      "        [1.0582, 1.1887, 0.9153]])\n",
      "tensor([[2.5560, 1.0656],\n",
      "        [1.0582, 1.1887],\n",
      "        [1.6055, 0.8582]])\n",
      "tensor([[2.5560, 1.0656],\n",
      "        [1.0582, 1.1887],\n",
      "        [1.6055, 0.8582]])\n",
      "0.8581721782684326\n",
      "tensor([1.6055, 0.8582, 0.9703])\n"
     ]
    }
   ],
   "source": [
    "# Slicing tensors\n",
    "print(x[:-1])\n",
    "print(x[:,:2])\n",
    "u = x[:,:2]\n",
    "print(u)\n",
    "u = x[2,1]\n",
    "print(u.item())\n",
    "print(x[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c7685b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Converting a torch tensor to a numpy array\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "a.add_(1)\n",
    "# Here we can notice as soon as we perform any operation in the torch tensor, then numpy array also gets affected\n",
    "# This is called the numpy bridge\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f708933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "tensor([2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Converting a numnpy array to a torch tensor\n",
    "# Same thing we will also have a numpy bridge here\n",
    "a = np.ones(2)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "892ee763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5560, 1.0656, 0.4801],\n",
      "        [1.0582, 1.1887, 0.9153],\n",
      "        [1.6055, 0.8582, 0.9703]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Moving the tensors to cuda\n",
    "\n",
    "x = x.cuda()\n",
    "os.system('CUDA_LAUNCH_BLOCKING=1')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78ebeb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2.], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    add_sum = b.cuda()\n",
    "    print(add_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d77acc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4, 5, 6]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Converting a list to a tensor\n",
    "ls = [2,3,4,5,6]\n",
    "to_ls = torch.tensor(ls)\n",
    "print(to_ls, to_ls.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b152339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3153,  1.2857, -1.5175,  0.1393, -0.0069],\n",
      "        [-1.0783,  0.2786, -0.5890, -0.5115, -0.8723],\n",
      "        [-1.1117, -0.2263, -1.4117, -1.0286, -0.2465],\n",
      "        [ 2.1026, -0.3923, -0.8967,  1.1783, -0.4872],\n",
      "        [ 0.5793, -0.4394, -0.7675, -1.0861, -0.3882]])\n",
      "tensor([[-0.9926, -0.7145,  0.4150],\n",
      "        [-0.5243,  0.8682, -0.7619]])\n",
      "tensor([[ 0.9485,  0.9568, -0.7950, -0.8767,  0.1593],\n",
      "        [-1.1366, -2.0665,  2.3545, -0.5904,  0.2500]])\n",
      "tensor([[-0.9926, -0.7145,  0.4150,  0.9485,  0.9568, -0.7950, -0.8767,  0.1593],\n",
      "        [-0.5243,  0.8682, -0.7619, -1.1366, -2.0665,  2.3545, -0.5904,  0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenating tensors\n",
    "f1 = torch.randn(2,5)\n",
    "t2 = torch.randn(3,5)\n",
    "# Concatenating along rows\n",
    "con1 = torch.cat([f1, t2])\n",
    "print(con1)\n",
    "f2 = torch.randn(2,3)\n",
    "print(f2)\n",
    "f3 = torch.randn(2,5)\n",
    "print(f3)\n",
    "# Concatenating along 1 dim [columns]\n",
    "con3 = torch.cat([f2,f3], 1)\n",
    "print(con3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8f8f568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5]])\n",
      "torch.Size([1, 5])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5]])\n",
      "torch.Size([5, 1])\n",
      "tensor([[[-0.2771,  0.5967,  0.3682,  0.6202],\n",
      "         [-1.0894,  0.1918,  1.4574,  0.2619],\n",
      "         [ 0.2236,  1.9963, -0.6731,  0.7798]],\n",
      "\n",
      "        [[-0.7252,  0.1376,  1.9654,  0.0042],\n",
      "         [-0.0485, -0.4292, -0.0868, -0.6094],\n",
      "         [ 0.0996, -0.5149, -0.3623, -0.3933]]])\n",
      "tensor([[ 0.3682,  1.4574, -0.6731],\n",
      "        [ 1.9654, -0.0868, -0.3623]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[[ 0.3682],\n",
      "         [ 1.4574],\n",
      "         [-0.6731]],\n",
      "\n",
      "        [[ 1.9654],\n",
      "         [-0.0868],\n",
      "         [-0.3623]]])\n",
      "torch.Size([2, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Adding dimensions to the tensors\n",
    "ten1 = torch.tensor([1,2,3,4,5])\n",
    "ten2 = torch.unsqueeze(ten1, 0)\n",
    "print(ten2)\n",
    "print(ten2.shape)\n",
    "ten3 = torch.unsqueeze(ten1, 1)\n",
    "print(ten3)\n",
    "print(ten3.shape)\n",
    "ten4 = torch.randn(2,3,4)\n",
    "print(ten4)\n",
    "tenc = ten4[:,:,2]\n",
    "print(tenc)\n",
    "print(tenc.shape)\n",
    "tend = torch.unsqueeze(tenc, 2)\n",
    "print(tend)\n",
    "print(tend.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7d31550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 7., 9.], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x7fe0419c99d0>\n",
      "tensor(21., grad_fn=<SumBackward0>)\n",
      "<SumBackward0 object at 0x7fe0412240a0>\n"
     ]
    }
   ],
   "source": [
    "# Autograd\n",
    "\n",
    "#  If autograd is set to true , then pytorch keeps track of the gradient \n",
    "x = torch.tensor([1., 2., 3], requires_grad=True)\n",
    "y = torch.tensor([4., 5., 6], requires_grad=True)\n",
    "\n",
    "# Computing the gradient\n",
    "z = x+y\n",
    "print(z)\n",
    "print(z.grad_fn)\n",
    "# If we keep on continuing\n",
    "s = z.sum()\n",
    "print(s)\n",
    "print(s.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "362c51f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# Lets backpropagate on s , we can fing the gradients of s with respect to x\n",
    "s.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28f3671e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "None\n",
      "<AddBackward0 object at 0x7fe02dc34a60>\n",
      "True\n",
      "None\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Default is requires_grad = false\n",
    "x = torch.randn(2,2)\n",
    "y = torch.randn(2,2)\n",
    "print(x.requires_grad, y.requires_grad)\n",
    "z = x+y\n",
    "# Thus we cant back prop\n",
    "print(z.grad_fn)\n",
    "# Another way of setting require grad to true\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "z = x+y\n",
    "print(z.grad_fn)\n",
    "print(z.requires_grad)\n",
    "\n",
    "# Z has the computation history that can relate to x and y\n",
    "new_z = z.detach()\n",
    "print(new_z.grad_fn)\n",
    "# z.detach returns a tensor that shares the same storage as 'z' but with the computation history forgotten. \n",
    "# It doesnt know anything about how it was computed. In other words its tensor that has broken away from its past history\n",
    "\n",
    "# Stopping tensors to stop tracking history\n",
    "print(x.requires_grad)\n",
    "print((x+10).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x+10).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1d062d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "pred = torch.randn(4,5)\n",
    "label = torch.randn(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cd493e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "mse = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e189a709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.8519e-01, 2.1675e-01, 9.2598e-03, 2.5043e-02, 1.6445e+00],\n",
       "        [1.1061e-01, 4.8832e-01, 1.7214e-01, 8.4170e-03, 1.1453e-06],\n",
       "        [2.5069e+01, 1.5267e+00, 6.1410e-02, 3.6202e-01, 1.9199e+00],\n",
       "        [6.7003e-03, 4.4402e-01, 1.8229e+01, 4.8144e+00, 1.2807e-02]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mse(pred, label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60d77de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7953)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean reduction stands for the mean of all the above elemenets\n",
    "mse = nn.MSELoss(reduction='mean')\n",
    "loss= mse(pred, label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cbab178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55.9055)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum reduction stands for the sum of all the above elements\n",
    "mse = nn.MSELoss(reduction='sum')\n",
    "loss=mse(pred, label)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "284f0894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7953)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scratch implementation of mse\n",
    "mse = ((pred-label)**2).mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64252641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55.9055)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = ((pred-label)**2).sum()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbb18b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 0., 0.],\n",
       "        [1., 1., 0., 1., 0.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary cross entropy \n",
    "label = torch.zeros(4,5).random_(0,2)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ef4ca83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7571)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg = nn.Sigmoid()\n",
    "bce = nn.BCELoss(reduction='mean')\n",
    "bce(sg(pred), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe03e360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7571)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BCE with logit loss\n",
    "bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "bce(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f9f5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid implementation\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1393c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7571293923188918\n"
     ]
    }
   ],
   "source": [
    "# scratch implemetation\n",
    "prednum = pred.numpy()\n",
    "lalnum = label.numpy()\n",
    "\n",
    "prednum = sigmoid(prednum)\n",
    "\n",
    "lossval = []\n",
    "for idx in range(len(lalnum)):\n",
    "    batchls = []\n",
    "    for idj in range(len(lalnum[0])):\n",
    "# if 1 then -log(x) or else -log(1-x)\n",
    "        batchls.append(-np.log(prednum[idx][idj]) if lalnum[idx][idj] == 1 else -np.log(1-prednum[idx][idj]))\n",
    "    lossval.append(batchls)\n",
    "print(np.mean(lossval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d8eab8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0338,  0.4319, -0.0487,  0.1131, -0.4337],\n",
       "        [ 0.0342,  0.3774, -0.3434, -0.3009,  0.0387],\n",
       "        [ 0.3433,  0.3227,  0.2714, -0.1950, -0.1475],\n",
       "        [-0.3630, -0.2725, -0.0703, -0.4428,  0.1671],\n",
       "        [ 0.1390,  0.3801, -0.1262,  0.1728, -0.1119]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Weight initialization\n",
    "layer = nn.Linear(5,5)\n",
    "layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9deb0a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3935, 2.8700, 1.7786, 0.9714, 1.6946],\n",
       "        [0.6508, 0.9485, 1.1507, 0.7879, 0.5309],\n",
       "        [0.8455, 2.0859, 1.4195, 2.5097, 1.4688],\n",
       "        [0.7639, 0.4242, 2.5178, 2.3848, 0.2044],\n",
       "        [1.7226, 1.5892, 0.8496, 1.6147, 2.4992]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uniform initialisation\n",
    "nn.init.uniform_(layer.weight.data ,a=0.0, b=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "28782815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8364,  2.2816, -1.1516, -0.6965,  1.4944],\n",
       "        [ 0.8730,  0.0351, -0.6428, -1.1610,  0.6280],\n",
       "        [-0.2186,  0.4613,  0.7571, -0.2126,  0.2457],\n",
       "        [ 0.2771, -0.3233, -0.0539,  0.6020,  0.6495],\n",
       "        [ 1.4403,  0.6352,  0.3383,  0.6251,  1.6101]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normal distribution\n",
    "nn.init.normal_(layer.weight.data, mean=0.0, std=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c9069f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0854,  0.0652,  0.2581,  0.2509, -0.2999],\n",
       "        [ 0.0171,  0.0035,  0.3003, -0.1946,  0.3058],\n",
       "        [-0.2565,  0.1600,  0.0123, -0.1609,  0.2886],\n",
       "        [-0.0546, -0.3542, -0.1709,  0.1001,  0.3660],\n",
       "        [-0.1649, -0.2011, -0.1517, -0.1989,  0.0550]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.normal_(layer.weight.data, mean=0.0, std=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ac0df440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constant initialisation\n",
    "nn.init.constant_(layer.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4892d838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c9796ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6e013b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7505, -0.2085,  0.7480,  0.6749, -0.6570],\n",
       "        [ 0.4072, -0.3302, -0.5706, -0.4058,  0.4960],\n",
       "        [-0.7058,  0.7702, -0.0217,  0.5984, -0.0398],\n",
       "        [-0.1148, -0.6094,  0.5956,  0.4466,  0.3286],\n",
       "        [ 0.3436, -0.4977,  0.3766,  0.6729,  0.4752]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xavier initialisation\n",
    "nn.init.xavier_uniform_(layer.weight.data, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc260325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1375, -0.2692, -0.7040,  0.6446,  0.3688],\n",
       "        [ 0.1992,  0.9466, -0.7689, -0.7558, -0.8629],\n",
       "        [ 0.4228,  0.1924,  0.5441,  0.3148,  0.1434],\n",
       "        [-0.1396, -0.4639,  0.3071,  0.2512,  0.0898],\n",
       "        [ 0.5552,  1.0036, -0.0120,  0.5545, -0.9677]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.xavier_normal_(layer.weight.data, gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe57667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
